{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from matplotlib.dates import MonthLocator, YearLocator\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "filename_test = 'test.csv'\n",
    "filename_train = 'train.csv'\n",
    "filename_store = 'store.csv'\n",
    "\n",
    "train = pd.read_csv(filename_train, header=0, low_memory=False)\n",
    "\n",
    "test = pd.read_csv(filename_test, header=0, low_memory=False)\n",
    "\n",
    "\n",
    "store_info = pd.read_csv(filename_store, header=0, low_memory=False)\n",
    "\n",
    "train.Date = pd.to_datetime(train.Date)\n",
    "test.Date = pd.to_datetime(test.Date)\n",
    "\n",
    "def print_missing_stats():\n",
    "    for data_name, data in {'TRAIN': train, 'TEST': test, 'STORE': store_info}.items():\n",
    "        print(data_name, ' (overall = %d)' % len(data))\n",
    "        for attribute in data.columns:\n",
    "            mask = data[attribute].isnull()\n",
    "            k = len(data[attribute][mask].tolist())\n",
    "            print('%5d (%2d%%)' % (k, 100*k/len(data)), 'missing values in ', attribute) \n",
    "        print()\n",
    "# print_missing_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(test[test.Open.isnull()])\n",
    "test.ix[test.Open.isnull(), 'Open'] = 1\n",
    "\n",
    "store_info.ix[store_info.CompetitionDistance.isnull(),\n",
    "         'CompetitionDistance'] = 0\n",
    "store_info.ix[store_info.CompetitionOpenSinceMonth.isnull(),\n",
    "         'CompetitionOpenSinceMonth'] = 0\n",
    "store_info.ix[store_info.CompetitionOpenSinceYear.isnull(),\n",
    "         'CompetitionOpenSinceYear'] = 0\n",
    "store_info.ix[store_info.Promo2SinceWeek.isnull(),\n",
    "         'Promo2SinceWeek'] = 0\n",
    "store_info.ix[store_info.Promo2SinceYear.isnull(),\n",
    "         'Promo2SinceYear'] = 0\n",
    "\n",
    "promo_intervals = [np.NaN] + list(store_info.PromoInterval.value_counts().index)\n",
    "store_info.PromoInterval = store_info.PromoInterval.map(lambda x: promo_intervals.index(x))\n",
    "# print_missing_stats()\n",
    "del promo_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/anaconda3/lib/python3.4/site-packages/IPython/kernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "date_range_train = pd.date_range('2013-01-01', '2015-06-13')\n",
    "date_range_test = pd.date_range('2015-06-14', '2015-07-31')\n",
    "\n",
    "# date_range_train = pd.date_range('2013-01-01', '2014-07-31')\n",
    "# date_range_test = pd.date_range('2014-08-01', '2014-09-17')\n",
    "\n",
    "train = train[train.Open == 1]\n",
    "validation = True\n",
    "if validation:\n",
    "    train_date_range = train[train.Date.isin(date_range_train)]\n",
    "else:\n",
    "    train_date_range = train\n",
    "#     date_range_test = pd.date_range('2015-08-01', '2015-09-17')\n",
    "\n",
    "    \n",
    "train_date_range['NumberDay'] = train_date_range.Date.map(lambda d:\n",
    "                                                       ((d - pd.datetime(2013, 1, 1))\n",
    "                                                        /np.timedelta64(1, 'D')).astype(int))\n",
    "groupby_features = ['Store', 'DayOfWeek', 'Promo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_aggregate(group):\n",
    "    weights = group['Weight']\n",
    "    sales = group['Sales']\n",
    "    return np.sum(np.array(weights) * np.array(sales)) / (np.sum(weights))\n",
    "\n",
    "def compute_RMSPE(test_labels, predicted_labels):\n",
    "    mask = test_labels.nonzero()\n",
    "    y = test_labels[mask]\n",
    "    y_hat = predicted_labels[mask]\n",
    "    return np.sqrt(np.mean(((y - y_hat)/y)**2))\n",
    "\n",
    "alphas, rmspe_s = [], []\n",
    "min_alpha, min_rmspe = 0., 1.\n",
    "                \n",
    "grid_space = [1]\n",
    "for alpha in grid_space:\n",
    "    ws = [0.33, 0.88, 0.88]\n",
    "    sigma = [33, 33, 134.2]    \n",
    "    def weight_function(x):\n",
    "        return ws[0]*np.exp(-(x - 221)**2/sigma[0]**2) + \\\n",
    "            ws[1]*np.exp(-(x - 577)**2/sigma[1]**2) + \\\n",
    "            ws[2]*np.exp(-(x - 941)**2/sigma[2]**2) \n",
    "            \n",
    "    train_date_range['Weight'] = train_date_range.NumberDay.map(weight_function)\n",
    "    if len(grid_space) <= 1:\n",
    "        pl.figure(figsize=(15,10))\n",
    "        pl.title('Weight function')\n",
    "    #         pl.plot(train_date_range['Date'], train_date_range['NumberDay'], 'k--')\n",
    "        pl.plot(train_date_range['Date'], train_date_range['Weight'], 'b-')\n",
    "    else:\n",
    "        print('trying alpha =', alpha, end='\\t')\n",
    "    grouped = train_date_range.groupby(groupby_features, as_index=False)\n",
    "    sales_predicted = pd.DataFrame(grouped.apply(custom_aggregate), columns=['PredictedSales']).reset_index()\n",
    "\n",
    "    if not validation and len(grid_space) <= 1:\n",
    "        test = pd.merge(test, store_info[['Store', 'CompetitionDistance']], on='Store', how='left')\n",
    "        df = pd.merge(test, sales_predicted, how='left', on=groupby_features)\n",
    "        df.ix[df.Open == 0, 'PredictedSales'] = 0\n",
    "        df.rename(columns={'PredictedSales': 'Sales'}, inplace=True)\n",
    "        df[['Id', 'Sales']].to_csv('prediction_simple.csv', index=False)\n",
    "        print('\\nResult was written to prediction_simple.csv')\n",
    "    else:\n",
    "        local_test = train[train.Date.isin(date_range_test)]\n",
    "        df = pd.merge(local_test, sales_predicted, how='left', on=groupby_features)\n",
    "        df.ix[df.Open == 0, 'PredictedSales'] = 0\n",
    "        loss_score = compute_RMSPE(np.array(df['Sales']), np.array(df['PredictedSales']))\n",
    "        if loss_score <= min_rmspe:\n",
    "            min_rmspe = loss_score\n",
    "            min_alpha = alpha\n",
    "        print('RMSPE =', loss_score, '\\nmin_alpha =', min_alpha, 'min_rmspe =', min_rmspe)\n",
    "        alphas.append(alpha)\n",
    "        rmspe_s.append(loss_score)\n",
    "\n",
    "    del sales_predicted, grouped, df\n",
    "\n",
    "if len(grid_space) > 1:\n",
    "    pl.figure(figsize=(15,10))\n",
    "    pl.title('grid space')\n",
    "    pl.plot(alphas, rmspe_s, 'r.--')\n",
    "    print('Min alpha =', min_alpha, 'Min RMSPE =', min_rmspe)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
