{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from matplotlib.dates import MonthLocator\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "filename_test = 'test.csv'\n",
    "filename_train = 'train.csv'\n",
    "filename_store = 'store.csv'\n",
    "\n",
    "train = pd.read_csv(filename_train, header=0, low_memory=False)\n",
    "\n",
    "test = pd.read_csv(filename_test, header=0, low_memory=False)\n",
    "\n",
    "\n",
    "store_info = pd.read_csv(filename_store, header=0, low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Date = pd.to_datetime(train.Date)\n",
    "\n",
    "test.Date = pd.to_datetime(test.Date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_missing_stats():\n",
    "    for data_name, data in {'TRAIN': train, 'TEST': test, 'STORE': store_info}.items():\n",
    "        print(data_name, ' (overall = %d)' % len(data))\n",
    "        for attribute in data.columns:\n",
    "            mask = data[attribute].isnull()\n",
    "            k = len(data[attribute][mask].tolist())\n",
    "            print('%5d (%2d%%)' % (k, 100*k/len(data)), 'missing values in ', attribute) \n",
    "        print()\n",
    "print_missing_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(test[test.Open.isnull()])\n",
    "test.ix[test.Open.isnull(), 'Open'] = 1\n",
    "\n",
    "store_info.ix[store_info.CompetitionDistance.isnull(),\n",
    "         'CompetitionDistance'] = store_info.CompetitionDistance.mean()\n",
    "store_info.ix[store_info.CompetitionOpenSinceMonth.isnull(),\n",
    "         'CompetitionOpenSinceMonth'] = int(store_info.CompetitionOpenSinceMonth.mode())\n",
    "store_info.ix[store_info.CompetitionOpenSinceYear.isnull(),\n",
    "         'CompetitionOpenSinceYear'] = int(store_info.CompetitionOpenSinceYear.mode())\n",
    "\n",
    "print_missing_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all sales by day of week and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, axes = pl.subplots(nrows=7, ncols=1, sharey=True, figsize=(20,100))\n",
    "\n",
    "# for day_of_week in range(1, 8):\n",
    "#     custom_df = train[(train['Open'] == 1) & (train['DayOfWeek'] == day_of_week)]\n",
    "#     gp_store = custom_df.groupby('Store')\n",
    "\n",
    "#     for store, group in gp_store:\n",
    "#         axes[day_of_week - 1].plot(group['Date'], group['Sales'], 'v--')\n",
    "\n",
    "#     gp_date = custom_df.groupby('Date')\n",
    "\n",
    "#     ts_mean = gp_date['Sales'].mean()\n",
    "#     ts_median = gp_date['Sales'].median()\n",
    "#     ts_mean.plot(style='r-', linewidth=5, ax=axes[day_of_week - 1], label='mean')\n",
    "#     ts_median.plot(style='b-', linewidth=5, ax=axes[day_of_week - 1], label='median')\n",
    "\n",
    "\n",
    "#     axes[day_of_week - 1].set_title('Day ' + str(day_of_week) + '. number of stores = ' + str(len(gp_store)))\n",
    "#     axes[day_of_week - 1].legend()\n",
    "#     axes[day_of_week - 1].xaxis.set_major_locator(MonthLocator())\n",
    "#     axes[day_of_week - 1].grid(True)\n",
    "# # pl.savefig('all_stores_and_median.png', format='png')\n",
    "# del fig\n",
    "# del axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting mean of sales by day of week with different values of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def construct_label_name(school_holiday, state_holiday, promo_flag, n_stores):\n",
    "#     string_school = 'NO SchoolHoliday. '\n",
    "#     string_state = 'NO StateHoliday. '\n",
    "#     string_promo = 'NO Promo. '\n",
    "#     if school_holiday == 1:\n",
    "#         string_school = string_school[3:]\n",
    "#     if promo_flag:\n",
    "#         string_promo = string_promo[3:]\n",
    "#     if state_holiday != '0':\n",
    "#         string_state = {'a': 'PublicHoliday. ',\n",
    "#                         'b': 'EasterHoliday. ',\n",
    "#                         'c':'Christmas. '}[state_holiday]\n",
    "#     string_stores = '(' + str(n_stores) + ' stores)'\n",
    "#     return string_school + string_state + string_promo + string_stores\n",
    "\n",
    "# fig, axes = pl.subplots(nrows=7, ncols=1, sharey=True, figsize=(20,100))\n",
    "# for day_of_week in range(1, 8):\n",
    "#     for school_holiday in [0, 1]:\n",
    "#         for state_holiday in ['0', 'a', 'b', 'c']:\n",
    "#             for promo_flag in [0, 1]:\n",
    "#                 custom_df = train[(train.Open == 1) & \n",
    "#                                   (train.DayOfWeek == day_of_week) &\n",
    "#                                   (train.Promo == promo_flag) & \n",
    "#                                   (train.SchoolHoliday == school_holiday) & \n",
    "#                                   (train.StateHoliday == state_holiday)]\n",
    "\n",
    "#                 gp_date = custom_df.groupby('Date')\n",
    "#                 gp_store = custom_df.groupby('Store')\n",
    "                \n",
    "#                 if list(gp_date.Sales):\n",
    "#                     ts_mean = gp_date.Sales.mean()\n",
    "#                     ts_mean.plot(style='v--', ax=axes[day_of_week - 1], \n",
    "#                                  label=construct_label_name(school_holiday, state_holiday,\n",
    "#                                                             promo_flag, len(gp_store)))\n",
    "    \n",
    "                \n",
    "#     custom_df = train[(train.Open == 1) & (train.DayOfWeek == day_of_week)]\n",
    "#     gp_date = custom_df.groupby('Date')\n",
    "#     gp_store = custom_df.groupby('Store')\n",
    "#     ts_mean = gp_date.Sales.mean()\n",
    "#     ts_mean.plot(style='r-', linewidth=1.5, ax=axes[day_of_week - 1],\n",
    "#                  label='mean (' + str(len(gp_store)) + ' stores)')\n",
    "#     axes[day_of_week - 1].set_title('Day ' + str(day_of_week))\n",
    "#     axes[day_of_week - 1].legend()\n",
    "#     axes[day_of_week - 1].xaxis.set_major_locator(MonthLocator())\n",
    "#     axes[day_of_week - 1].grid(True)\n",
    "    \n",
    "    \n",
    "# # pl.savefig('median_decomposition.png', format='png')\n",
    "# del fig\n",
    "# del axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train, data_train_labels, data_test = [], [], []\n",
    "\n",
    "date_range_train = pd.date_range('2013-01-01', '2014-12-31')\n",
    "date_range_test = pd.date_range('2015-01-01', '2015-12-31')\n",
    "\n",
    "validation = False\n",
    "stores_numbers = range(1, 1116)\n",
    "# stores_numbers = np.random.randint(1115, size=20) + 1\n",
    "\n",
    "train_date_range = train\n",
    "if validation:\n",
    "    train_date_range = train[train.Date.isin(date_range_train)]\n",
    "\n",
    "for store in stores_numbers:    \n",
    "    print(store, end=' ')\n",
    "    custom_store_df = train_date_range[train_date_range.Store == store]\n",
    "    custom_store_info_df = store_info[store_info.Store == store]\n",
    "    for day_of_week in range(1, 8):\n",
    "        custom_store_week_df = custom_store_df[(custom_store_df.DayOfWeek == day_of_week)]\n",
    "        for promo in [0, 1]:\n",
    "            df_promo = custom_store_week_df[custom_store_week_df.Promo == promo]\n",
    "            for school_holiday in [0, 1]:\n",
    "                df = df_promo[df_promo.SchoolHoliday == school_holiday]\n",
    "                for state_holiday in ['0', 'a', 'b', 'c']:\n",
    "                    if not df.empty:\n",
    "                        m = df.Sales.median()\n",
    "                        data_train.append([store, day_of_week, promo, state_holiday,\n",
    "                                           custom_store_info_df.StoreType.iloc[0],\n",
    "                                           custom_store_info_df.Assortment.iloc[0], school_holiday])\n",
    "#                         data_train.append([store, day_of_week, promo, state_holiday])\n",
    "                        data_train_labels.append(m)\n",
    "print('\\nConstructed data_train')\n",
    "data_train = np.asarray(data_train)\n",
    "holiday_encoder = LabelEncoder()\n",
    "storetype_encoder = LabelEncoder()\n",
    "assortment_encoder = LabelEncoder()\n",
    "holiday_encoder.fit(['0', 'a', 'b', 'c'])\n",
    "storetype_encoder.fit(['a', 'b', 'c', 'd'])\n",
    "assortment_encoder.fit(['a', 'b', 'c'])\n",
    "data_train[:, 3] = holiday_encoder.transform(data_train[:, 3])\n",
    "data_train[:, 4] = storetype_encoder.transform(data_train[:, 4])\n",
    "data_train[:, 5] = assortment_encoder.transform(data_train[:, 5])\n",
    "print('Encoded categorical type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'StoreType', 'Assortment', 'SchoolHoliday']\n",
    "def construct_test(test, holiday_encoder, storetype_encoder, assortment_encoder):\n",
    "    temp = pd.merge(test, store_info, on='Store', how='left') \n",
    "    temp = temp[features]\n",
    "    temp = np.asarray(temp)\n",
    "    temp[:, 3] = holiday_encoder.transform(temp[:, 3])\n",
    "    temp[:, 4] = storetype_encoder.transform(temp[:, 4])\n",
    "    temp[:, 5] = assortment_encoder.transform(temp[:, 5])\n",
    "    return temp\n",
    "\n",
    "if validation:\n",
    "    local_test = train[(train.Date.isin(date_range_test)) & (train.Store.isin(stores_numbers))]\n",
    "    local_test_labels = np.asarray(local_test.Sales)\n",
    "    local_test = construct_test(local_test, holiday_encoder, storetype_encoder, assortment_encoder)\n",
    "else:\n",
    "    data_test = construct_test(test, holiday_encoder, storetype_encoder, assortment_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.externals.six import StringIO  \n",
    "# import pydot\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "clf.fit(data_train, data_train_labels)\n",
    "print(*zip(features, clf.feature_importances_))\n",
    "# tree.export_graphviz(clf, out_file='decision.dot')\n",
    "# graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "# graph.write_pdf(\"decision.pdf\") \n",
    "\n",
    "def compute_RMSPE(test_labels, predicted_labels):\n",
    "        mask = test_labels.nonzero()\n",
    "        if len(mask) == 0:\n",
    "            return 0\n",
    "        return np.sqrt(((np.ones(len(mask)) - predicted_test_labels[mask]/test_labels[mask])**2).sum()/len(mask))\n",
    "\n",
    "if validation:\n",
    "    predicted_test_labels = np.asarray(clf.predict(local_test), dtype=int) #CAUTION!\n",
    "    loss_score = compute_RMSPE(local_test_labels, predicted_test_labels)\n",
    "    print('RMSPE =', loss_score)\n",
    "    pl.figure(figsize=(20,7))\n",
    "    pl.plot(local_test_labels, 'b.', label='real')\n",
    "    pl.plot(predicted_test_labels, 'r.', label='predicted')\n",
    "    pl.legend()\n",
    "    \n",
    "else:\n",
    "    data_test_labels = np.asarray(clf.predict(data_test), dtype=int) \n",
    "    test['Sales'] = data_test_labels\n",
    "    test[['Id', 'Sales']].to_csv('prediction.csv', index=False)\n",
    "    print('\\nresult was written to prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting prediction (mean and median by stores) by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not validation:\n",
    "    fig, axes = pl.subplots(nrows=7, ncols=1, sharey=True, figsize=(20,100))\n",
    "    \n",
    "    train_open = train[train.Open == 1]\n",
    "    test_open = test[test.Open == 1]\n",
    "    for day_of_week in range(1, 8):\n",
    "        custom_df = train_open[train_open.DayOfWeek == day_of_week]\n",
    "        gp_date = custom_df.groupby('Date')\n",
    "\n",
    "        ts_mean = gp_date.Sales.mean()\n",
    "        ts_mean.plot(style='r-', linewidth=2, ax=axes[day_of_week - 1], label='mean')\n",
    "        ts_median = gp_date.Sales.median()\n",
    "        ts_median.plot(style='b-', linewidth=2, ax=axes[day_of_week - 1], label='median')\n",
    "        \n",
    "\n",
    "        custom_df = test_open[test_open.DayOfWeek == day_of_week]\n",
    "        gp_date = custom_df.groupby('Date')\n",
    "\n",
    "        ts_mean = gp_date.Sales.mean()\n",
    "        ts_mean.plot(style='k--', linewidth=2, ax=axes[day_of_week - 1], label='mean predicted')\n",
    "        ts_median = gp_date.Sales.median()\n",
    "        ts_median.plot(style='y--', linewidth=2, ax=axes[day_of_week - 1], label='median predicted')\n",
    "\n",
    "\n",
    "        axes[day_of_week - 1].xaxis.set_major_locator(MonthLocator())\n",
    "        axes[day_of_week - 1].set_title('Day ' + str(day_of_week))\n",
    "        axes[day_of_week - 1].legend()\n",
    "        axes[day_of_week - 1].grid(True)\n",
    "\n",
    "    del fig\n",
    "    del axes"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
