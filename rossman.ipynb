{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from matplotlib.dates import MonthLocator, YearLocator\n",
    "from sklearn.linear_model import ElasticNet, Ridge, RidgeCV, ElasticNetCV\n",
    "from sklearn.ensemble.forest import RandomForestRegressor, ExtraTreesRegressor\n",
    "from scipy.sparse import csc_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.mpl_style', 'default')\n",
    "pl.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "def print_missing_stats(train, test, store_info):\n",
    "    for data_name, data in {'TRAIN': train, 'TEST': test, 'STORE': store_info}.items():\n",
    "        print(data_name, ' (overall = %d)' % len(data))\n",
    "        for attribute in data.columns:\n",
    "            mask = data[attribute].isnull()\n",
    "            k = len(data[attribute][mask])\n",
    "            print('%5d (%2d%%)' % (k, 100*k/len(data)), 'missing values in ', attribute) \n",
    "        print()\n",
    "\n",
    "def load_data(filename_train, filename_test, filename_store, print_missing=False):\n",
    "\n",
    "    train = pd.read_csv(filename_train, header=0, low_memory=False)\n",
    "    test = pd.read_csv(filename_test, header=0, low_memory=False)\n",
    "    store_info = pd.read_csv(filename_store, header=0, low_memory=False)\n",
    "\n",
    "    train.Date = pd.to_datetime(train.Date)\n",
    "    test.Date = pd.to_datetime(test.Date)\n",
    "    \n",
    "    if print_missing:\n",
    "        print('BEFORE:')\n",
    "        print_missing_stats(train, test, store_info)\n",
    "    \n",
    "    test.Open = test.Open.fillna(1)\n",
    "\n",
    "    store_info.CompetitionDistance = store_info.CompetitionDistance.fillna(0)\n",
    "    store_info.CompetitionOpenSinceMonth = store_info.CompetitionOpenSinceMonth.fillna(0).astype(int)\n",
    "    store_info.CompetitionOpenSinceYear = store_info.CompetitionOpenSinceYear.fillna(0).astype(int)\n",
    "    store_info.Promo2SinceWeek = store_info.Promo2SinceWeek.fillna(0).astype(int)\n",
    "    store_info.Promo2SinceYear = store_info.Promo2SinceYear.fillna(0).astype(int)\n",
    "\n",
    "    promo_intervals = [np.NaN] + list(store_info.PromoInterval.value_counts().index)\n",
    "    store_info.PromoInterval = store_info.PromoInterval.map(lambda x: promo_intervals.index(x))\n",
    "    \n",
    "    if print_missing:\n",
    "        print('AFTER:')\n",
    "        print_missing_stats(train, test, store_info)\n",
    "    return train, test, store_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_all_store_sales(train):\n",
    "    fig, axes = pl.subplots(nrows=7, ncols=1, sharey=True, figsize=(20,100))\n",
    "\n",
    "    open_df = train[train.Open == 1]\n",
    "    for day_of_week in range(1, 8):\n",
    "        custom_df = open_df[open_df.DayOfWeek == day_of_week] \n",
    "        gp_store = custom_df.groupby('Store')\n",
    "\n",
    "        for store, group in gp_store:\n",
    "            axes[day_of_week - 1].plot(group['Date'], group['Sales'], 'v--')\n",
    "\n",
    "        gp_date = custom_df.groupby('Date')\n",
    "\n",
    "        ts_mean = gp_date['Sales'].mean()\n",
    "        ts_median = gp_date['Sales'].median()\n",
    "        ts_mean.plot(style='r-', linewidth=5, ax=axes[day_of_week - 1], label='mean')\n",
    "        ts_median.plot(style='b-', linewidth=5, ax=axes[day_of_week - 1], label='median')\n",
    "\n",
    "\n",
    "        axes[day_of_week - 1].set_title('Day ' + str(day_of_week) + '. number of stores = ' + str(len(gp_store)))\n",
    "        axes[day_of_week - 1].legend()\n",
    "        axes[day_of_week - 1].xaxis.set_major_locator(MonthLocator())\n",
    "        axes[day_of_week - 1].grid(True)\n",
    "    pl.savefig('all_stores_and_median.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def construct_label_name(school_holiday, state_holiday, promo_flag, n_stores):\n",
    "    string_school = 'NO SchoolHoliday. '\n",
    "    string_state = 'NO StateHoliday. '\n",
    "    string_promo = 'NO Promo. '\n",
    "    if school_holiday == 1:\n",
    "        string_school = string_school[3:]\n",
    "    if promo_flag:\n",
    "        string_promo = string_promo[3:]\n",
    "    if state_holiday != '0':\n",
    "        string_state = {'a': 'PublicHoliday. ',\n",
    "                        'b': 'EasterHoliday. ',\n",
    "                        'c':'Christmas. '}[state_holiday]\n",
    "    string_stores = '(' + str(n_stores) + ' stores)'\n",
    "    return string_school + string_state + string_promo + string_stores\n",
    "\n",
    "def plot_mean_decomposition(train):\n",
    "    fig, axes = pl.subplots(nrows=7, ncols=1, sharey=True, figsize=(20,100))\n",
    "\n",
    "    open_df = train[train.Open == 1]\n",
    "    for day_of_week in range(1, 8):\n",
    "        day_df = open_df[open_df.DayOfWeek == day_of_week]\n",
    "        for school_holiday in [0, 1]:\n",
    "            school_df = day_df[day_df.SchoolHoliday == school_holiday]\n",
    "            for state_holiday in ['0', 'a', 'b', 'c']:\n",
    "                state_df = school_df[school_df.StateHoliday == state_holiday]\n",
    "                for promo_flag in [0, 1]:\n",
    "                    custom_df = state_df[state_df.Promo == promo_flag]\n",
    "                    if not custom_df.empty:\n",
    "                        gp_date = custom_df.groupby('Date')\n",
    "                        gp_store = custom_df.groupby('Store')\n",
    "\n",
    "                        ts_mean = gp_date.Sales.mean()\n",
    "                        axes[day_of_week - 1].plot(ts_mean.index, ts_mean, 'v--', \n",
    "                                                   label=construct_label_name(school_holiday, state_holiday, \n",
    "                                                                              promo_flag, len(gp_store)))\n",
    "\n",
    "        custom_df = day_df\n",
    "        gp_date = custom_df.groupby('Date')\n",
    "        gp_store = custom_df.groupby('Store')\n",
    "        ts_mean = gp_date.Sales.mean()\n",
    "        ts_mean.plot(style='r-', linewidth=1.5, ax=axes[day_of_week - 1],\n",
    "                     label='mean (' + str(len(gp_store)) + ' stores)')\n",
    "        axes[day_of_week - 1].set_title('Day ' + str(day_of_week))\n",
    "        axes[day_of_week - 1].legend()\n",
    "        axes[day_of_week - 1].xaxis.set_major_locator(MonthLocator())\n",
    "        axes[day_of_week - 1].grid(True)\n",
    "    \n",
    "    \n",
    "    pl.savefig('median_decomposition.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dates_CV(k):\n",
    "    if k >= 16:\n",
    "        k = 15\n",
    "        print('maximum number of cross-validation folds is 15')\n",
    "    date_range = pd.date_range('2013-01-01', '2015-07-31')\n",
    "    for i in range(k):\n",
    "        temp_date_range = date_range.shift(-i*48)[48*i:]\n",
    "        train_date_range = temp_date_range[:-48]\n",
    "        test_date_range = temp_date_range[-48:] \n",
    "        yield train_date_range, test_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_with_store(data, store_info):    \n",
    "    store_features = ['Store', 'StoreType', 'Assortment','CompetitionDistance', \n",
    "                      'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\n",
    "                      'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "    data = pd.merge(data, store_info[store_features], on='Store', how='left')\n",
    "    return data\n",
    "\n",
    "def get_dummies_values(series, prefix, values):\n",
    "    new_series = pd.get_dummies(series, prefix=prefix).to_sparse(fill_value=0)\n",
    "    for value in values:\n",
    "        column_name = prefix + '_' + str(value)\n",
    "        if column_name not in new_series.columns:\n",
    "            new_series = new_series.join(pd.DataFrame(np.zeros(len(new_series), dtype=int), index=new_series.index,\n",
    "                                                   columns=[column_name]))\n",
    "    columns = sorted(new_series.columns)\n",
    "    return new_series[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_some_features(data):\n",
    "    data['Day'] = data.Date.map(lambda d: d.day).astype(int)\n",
    "    data['Month'] = data.Date.map(lambda d: d.month).astype(int)\n",
    "    data['Week'] = data.Date.map(lambda d: d.week).astype(int)\n",
    "    data['DayOfYear'] = data.Date.map(lambda d: d.dayofyear).astype(int)\n",
    "    data['Year'] = data.Date.map(lambda d: d.year)\n",
    "   \n",
    "    data['DiffToday'] = ((pd.datetime(2015, 9, 18) - data.Date)\n",
    "                                     / np.timedelta64(1, 'D')).astype(int)\n",
    "    data['DiffNewYear'] = data.Date.map(lambda d: (min(d - pd.datetime(d.year, 1, 1),\n",
    "                                  pd.datetime(d.year + 1, 12, 31) - d) / np.timedelta64(1, 'D')).astype(int))\n",
    "    data['DiffFoolDay'] = data.Date.map(lambda d: ((d - pd.datetime(d.year, 4, 1))\n",
    "                                                                           / np.timedelta64(1, 'D')).astype(int))\n",
    "    \n",
    "    data['DiffCompetitionYear'] = data['Year'] - data['CompetitionOpenSinceYear']\n",
    "    data.ix[data.CompetitionOpenSinceYear == 0, 'DiffCompetitionYear'] = 0\n",
    "    \n",
    "    data = data.join(get_dummies_values(data.StateHoliday, prefix='StateHoliday', values=['0', 'a', 'b', 'c']))\n",
    "    data = data.join(get_dummies_values(data.Month, prefix='Month', values=np.arange(1, 13)))\n",
    "    data = data.join(get_dummies_values(data.StoreType, prefix='StoreType', values=['a', 'b', 'c', 'd']))\n",
    "    data = data.join(get_dummies_values(data.Assortment, prefix='Assortment', values=['a', 'b', 'c']))\n",
    "    data = data.join(get_dummies_values(data.DayOfWeek, prefix='DayOfWeek', values=np.arange(1, 8)))\n",
    "    data = data.join(get_dummies_values(data.CompetitionOpenSinceMonth, prefix='CompetitionOpenSinceMonth',\n",
    "                                        values=np.arange(1, 13)))\n",
    "    data = data.join(get_dummies_values(data.Year, prefix='Year', values=[2013, 2014, 2015]))\n",
    "    data = data.join(get_dummies_values(data.PromoInterval, prefix='PromoInterval', values=np.arange(4)))\n",
    "    \n",
    "    data['DayMonthChange'] = data.Day.map(lambda x: 28 <= x <= 31 or 1 <= x <= 4)\n",
    "    data['DayMonthAfterMiddle'] = data.Day.map(lambda x: 19 <= x <= 26)\n",
    "    data = data.join(get_dummies_values(data.Week.apply(lambda x: x % 4), prefix='Week', values=np.arange(4)))\n",
    "    \n",
    "    del data['StateHoliday'], data['Month'], data['Week']\n",
    "    del data['StoreType'], data['Assortment'], data['DayOfWeek']\n",
    "    del data['CompetitionOpenSinceMonth'], data['Year'], data['PromoInterval']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_data(data, store_info, train_features):\n",
    "    data = merge_with_store(data[train_features], store_info)\n",
    "    data = construct_some_features(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main_feature_construction(data):\n",
    "    train_data, test_data, store_info = data\n",
    "    train_data = train_data[train_data.Open == 1]\n",
    "    \n",
    "    train_features = ['Store', 'DayOfWeek', 'Date', 'Promo', 'SchoolHoliday', 'StateHoliday']\n",
    "    \n",
    "    train_data = construct_data(train_data, store_info, train_features + ['Sales'])\n",
    "    columns = [x for x in train_data.columns if x != 'Sales']\n",
    "    train_data = train_data[columns + ['Sales']]\n",
    "    test_data = construct_data(test_data, store_info, train_features)\n",
    "    \n",
    "    assert all([str(x) == str(y) for x, y in zip(list(train_data.columns), list(test_data.columns) + ['Sales'])])\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_column_indices(dataframe, column_name):\n",
    "    assert dataframe.columns[0] == column_name\n",
    "    column_indices = dataframe.groupby(column_name).indices\n",
    "    data_column_indices = []\n",
    "    for key in sorted(column_indices.keys()):\n",
    "        data_column_indices.append((key - 1, column_indices[key]))\n",
    "    return data_column_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_CV(train_data, number_of_folds=1, feature_selection=None, print_verbose=False, algorithm='rf'):\n",
    "    for i, date_ranges in enumerate(get_dates_CV(number_of_folds)):\n",
    "        date_range_train, date_range_test = date_ranges\n",
    "        if print_verbose:\n",
    "            print('Fold #%d' % (i+1))\n",
    "            print('     Train -> ', [str(date_ranges[0][0]), str(date_ranges[0][-1])])\n",
    "            print('Validation -> ', [str(date_ranges[1][0]), str(date_ranges[1][-1])])\n",
    "        \n",
    "        train_fold = train_data[train_data.Date.isin(date_range_train)]\n",
    "        test_fold = train_data[train_data.Date.isin(date_range_test)]\n",
    "        train_fold_labels = np.array(train_fold.Sales)\n",
    "        test_fold_labels = np.array(test_fold.Sales)\n",
    "        del train_fold['Date'], test_fold['Date'], train_fold['Sales'], test_fold['Sales']\n",
    "        \n",
    "        if feature_selection:\n",
    "            train_fold = train_fold[feature_selection]\n",
    "            test_fold = test_fold[feature_selection]\n",
    "        if algorithm in ['ridge', 'ens_rf']:\n",
    "            train_store_indices = get_column_indices(train_fold, 'Store')\n",
    "            test_store_indices = get_column_indices(test_fold, 'Store')\n",
    "        else:\n",
    "            train_store_indices, test_store_indices = None, None\n",
    "        yield np.array(train_fold), train_fold_labels, np.array(test_fold), \\\n",
    "            test_fold_labels, train_fold.columns, train_store_indices, test_store_indices\n",
    "\n",
    "def get_all_data(train_data, test_data, feature_selection=None, print_verbose=False, algorithm='rf'):\n",
    "    print('Train -> all dates')\n",
    "    print(' Test -> need to predict')\n",
    "    train_array_labels = np.array(train_data.Sales)\n",
    "    train_array = train_data[[x for x in train_data.columns if x not in ['Sales', 'Date']]] \n",
    "    test_array = test_data[[x for x in test_data.columns if x != 'Date']]\n",
    "    \n",
    "    if feature_selection:\n",
    "        train_array = train_array[feature_selection]\n",
    "        test_array = test_array[feature_selection]\n",
    "    \n",
    "    if algorithm in ['ridge', 'ens_rf']:\n",
    "        train_store_indices = get_column_indices(train_array, 'Store')\n",
    "        test_store_indices = get_column_indices(test_array, 'Store')\n",
    "    else:\n",
    "        train_store_indices, test_store_indices = None, None \n",
    "        \n",
    "    return np.array(train_array), train_array_labels, np.array(test_array), train_array.columns, \\\n",
    "        train_store_indices, test_store_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_feature_importances(clf, features):\n",
    "    print()\n",
    "    if isinstance(clf, list) and hasattr(clf[0], 'coef_'):\n",
    "        coefs = [clf_i.coef_ for clf_i in clf]\n",
    "        importances = np.mean(coefs, axis=0)\n",
    "        pl.title('Coeffs of linear model')\n",
    "        std = np.std(coefs, axis=0)\n",
    "    elif isinstance(clf, list) and hasattr(clf[0], 'feature_importances_'):\n",
    "        importances_for_store = [clf_i.feature_importances_ for clf_i in clf]\n",
    "        importances = np.mean(importances_for_store, axis=0)\n",
    "        pl.title('Feature Importance mean')\n",
    "        std = np.std(importances_for_store, axis=0)\n",
    "    elif hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "        pl.title('Feature Importance')\n",
    "    \n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    for i, k in enumerate(sorted_indices):\n",
    "        print('%2d (feature %2d):' % (i, k), features[k], 'Value = %.5f' % importances[k])\n",
    "    print([features[k] for k in sorted_indices])\n",
    "    \n",
    "    pl.bar(range(len(features)), importances[sorted_indices], color='r',\n",
    "           yerr=std[sorted_indices], align='center')\n",
    "    pl.xticks(range(len(features)), sorted_indices)\n",
    "    pl.xlim([-1, len(features) + 1])\n",
    "#     pl.savefig('feature_importance.png', format='png')\n",
    "\n",
    "def compute_RMSPE(test_labels, predicted_labels):\n",
    "    mask = test_labels.nonzero()\n",
    "    y = test_labels[mask]\n",
    "    y_hat = predicted_labels[mask]\n",
    "    return np.sqrt(np.mean(((y - y_hat)/y)**2))\n",
    "\n",
    "def visualize_RMSPE(test_labels, predicted_labels, step = 0.05):\n",
    "    for i in np.arange(0, 1, step):\n",
    "        pl.figure(figsize=(20,7))\n",
    "        pl.plot(test_labels[i*len(test_labels):(i+step)*len(test_labels)],\n",
    "                'b.', label='real')\n",
    "        pl.plot(predicted_labels[i*len(predicted_labels):(i+step)*len(predicted_labels)],\n",
    "                'r.', label='predicted')\n",
    "        pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_predict_model(train_array, train_array_labels, test_array, feature_names, algorithm='ens_rf', alpha=None,\n",
    "                      train_store_indices=None, test_store_indices=None, print_importances=True):\n",
    "    \n",
    "    if algorithm in ['rf', 'extrees']:\n",
    "        if algorithm == 'rf':\n",
    "            clf = RandomForestRegressor(n_estimators=80, n_jobs=-1, min_samples_leaf=2,\n",
    "                                        max_features=0.46)\n",
    "        elif algorithm == 'extrees':\n",
    "            clf = ExtraTreesRegressor(n_estimators=80, n_jobs=-1, max_features=0.46, min_samples_leaf=2)\n",
    "        \n",
    "        clf.fit(train_array, np.log(train_array_labels + 1.))\n",
    "        if print_importances:\n",
    "            visualize_feature_importances(clf, feature_names)\n",
    "\n",
    "        test_predicted_labels = np.exp(clf.predict(test_array)) - 1\n",
    "        \n",
    "    elif algorithm in ['ridge', 'ens_rf']:\n",
    "        if algorithm == 'ridge':\n",
    "            clfs = [Ridge(alpha=10**-3,normalize=True) for x in range(1115)]\n",
    "        elif algorithm == 'ens_rf':\n",
    "            clfs = [RandomForestRegressor(n_estimators=90, max_features=0.4,\n",
    "                                          min_samples_leaf=3, max_depth=9) for x in range(1115)]\n",
    "        \n",
    "        assert len(train_store_indices) == 1115\n",
    "        \n",
    "        for i, store_indices in train_store_indices:\n",
    "            clfs[i].fit(train_array[store_indices, 1:], np.log(train_array_labels[store_indices] + 1.))\n",
    "        \n",
    "        \n",
    "        test_predicted_labels = np.zeros(len(test_array))\n",
    "        for i, store_indices in test_store_indices:\n",
    "            test_predicted_labels[store_indices] = np.exp(clfs[i].predict(test_array[store_indices, 1:])) - 1.\n",
    "\n",
    "        if print_importances:\n",
    "            visualize_feature_importances(clfs, feature_names[1:])\n",
    "    elif algorithm == 'xgb':\n",
    "        dtrain = xgb.DMatrix(train_array, train_array_labels)\n",
    "        dtest = xgb.DMatrix(test_array)\n",
    "        param = {\n",
    "            'bst:eta':0.3, 'bst:max_depth':18, 'bst:colsample_bytree':0.7\n",
    "        }\n",
    "        n_round=alpha\n",
    "        bst = xgb.train(param, dtrain, n_round)\n",
    "        if print_importances:\n",
    "            xgb.plot_importance(bst)\n",
    "        test_predicted_labels = bst.predict(dtest)\n",
    "        del dtrain, dtest, bst\n",
    "    else:\n",
    "        assert False\n",
    "    return test_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_selection(algorithm):\n",
    "    if algorithm in ['ridge', 'ens_rf']:\n",
    "        if algorithm == 'ens_rf':\n",
    "            feature_selection = ['Store', 'Promo', 'DayOfWeek_6', 'Day', 'DiffToday', 'DayOfWeek_1', 'DiffFoolDay',\n",
    "                                 'DiffNewYear', 'DayOfYear', 'DayOfWeek_5', 'DayOfWeek_2', 'DayOfWeek_4', 'DayOfWeek_3',\n",
    "                                 'DayOfWeek_7', 'Year_2013', 'SchoolHoliday', 'DiffCompetitionYear', 'Month_5',\n",
    "                                 'Year_2014', 'Year_2015', 'Month_12', 'Month_4', 'Month_7', 'Month_8', 'Month_3',\n",
    "                                 'Month_6', 'Month_9', 'Month_2', 'Month_10', 'StateHoliday_0', 'Month_1', 'Month_11', \n",
    "                                 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c']\n",
    "            feature_selection += ['DayMonthChange', 'DayMonthAfterMiddle']\n",
    "            feature_selection += ['Week_' + str(i) for i in range(4)]\n",
    "        elif algorithm == 'ridge':   \n",
    "            feature_selection = ['Store', 'Promo', 'Month_12', 'DayOfWeek_1', 'SchoolHoliday', 'Month_5', 'Month_3', 'Month_4', 'DayOfWeek_5', 'Month_2', 'Month_1', 'StateHoliday_0', 'Year_2014', 'Year_2015', 'Month_6']\n",
    "            feature_selection += ['StateHoliday_c', 'StateHoliday_b', 'DayOfWeek_7', 'StateHoliday_a', 'DayOfWeek_2', 'Year_2013', 'Month_11', 'Month_7', 'DayOfWeek_6', 'DayOfWeek_4', 'DayOfWeek_3', 'Month_8', 'Month_10', 'Month_9']\n",
    "            feature_selection += ['DiffCompetitionYear'] + ['Week_0']\n",
    "            feature_selection += ['DayMonthChange', 'DayMonthAfterMiddle']\n",
    "        if feature_selection:\n",
    "            assert feature_selection[0] == 'Store' #Store must be the first column for algorithms for every store\n",
    "    else:\n",
    "        feature_selection = ['CompetitionDistance', 'Promo', 'Store', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'DiffCompetitionYear', 'Promo2SinceWeek', 'DayOfWeek_6', 'DiffToday', 'DayOfWeek_1', 'DiffNewYear', 'DiffFoolDay', 'StoreType_a', 'Day', 'DayOfYear', 'StoreType_b', 'Assortment_a', 'StoreType_d', 'CompetitionOpenSinceMonth_3', 'StoreType_c', 'Assortment_c', 'CompetitionOpenSinceMonth_5', 'DayMonthChange', 'CompetitionOpenSinceMonth_9', 'CompetitionOpenSinceMonth_8', 'CompetitionOpenSinceMonth_4', 'CompetitionOpenSinceMonth_12', 'CompetitionOpenSinceMonth_11', 'PromoInterval_3', 'CompetitionOpenSinceMonth_7', 'DayOfWeek_7', 'CompetitionOpenSinceMonth_10', 'CompetitionOpenSinceMonth_6', 'CompetitionOpenSinceMonth_2', 'CompetitionOpenSinceMonth_0', 'DayOfWeek_5', 'PromoInterval_1', 'PromoInterval_2', 'PromoInterval_0', 'CompetitionOpenSinceMonth_1', 'DayOfWeek_2', 'DayMonthAfterMiddle', 'Year_2013', 'SchoolHoliday', 'DayOfWeek_4', 'DayOfWeek_3', 'Month_12', 'Year_2014', 'Week_0', 'Month_5', 'Year_2015'] \n",
    "    return feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_score(train_data, number_of_folds, grid_space=[0], feature_selection=None,\n",
    "                    algorithm='ridge', print_importances=True):\n",
    "    \"\"\" to compute min alpha len(grid_space) must be > 1 \"\"\"\n",
    "    print(str(algorithm).upper(), 'is working...')\n",
    "    if len(grid_space) <= 1:\n",
    "        print_verbose_data = True\n",
    "    else:\n",
    "        print_verbose_data = False\n",
    "        alphas, scores = [], []\n",
    "        min_alpha, min_score = 1., 10**5\n",
    "        \n",
    "    visualize_rmspe = False\n",
    "    for alpha in grid_space:\n",
    "        if len(grid_space) > 1:\n",
    "            print('alpha =', alpha)\n",
    "        rmspe_cv = 0.  \n",
    "        predicted_labels = []\n",
    "        test_labels = []\n",
    "        for i, data_fold in enumerate(get_data_CV(train_data, number_of_folds, feature_selection=feature_selection, \n",
    "                                                  print_verbose=print_verbose_data, algorithm=algorithm)):\n",
    "            train_fold, train_fold_labels, test_fold, test_fold_labels, feature_names,\\\n",
    "            train_store_indices, test_store_indices = data_fold\n",
    "            \n",
    "            if i == 0 and len(grid_space) <= 1:\n",
    "                n = len(feature_names)\n",
    "                if algorithm not in ['ridge', 'ens_rf']:\n",
    "                    n = n + 1\n",
    "                print('number of features =', n - 1)\n",
    "            else:\n",
    "                print_importances = False\n",
    "            \n",
    "            test_predicted_labels = fit_predict_model(train_fold, train_fold_labels, test_fold, \n",
    "                                                      feature_names=feature_names, algorithm=algorithm,\n",
    "                                                      print_importances=print_importances,\n",
    "                                                      train_store_indices=train_store_indices,\n",
    "                                                      test_store_indices=test_store_indices, alpha=alpha)\n",
    "            \n",
    "            rmspe_score = compute_RMSPE(test_fold_labels, test_predicted_labels)\n",
    "            if visualize_rmspe:\n",
    "                visualize_RMSPE(test_fold_labels, test_predicted_labels)\n",
    "            \n",
    "            print('some rmspe_score = %1.8f' % rmspe_score)\n",
    "            rmspe_cv += rmspe_score\n",
    "            if len(grid_space) <= 1:\n",
    "                predicted_labels.append(test_predicted_labels)\n",
    "                test_labels.append(test_fold_labels)\n",
    "            \n",
    "        del train_fold, train_fold_labels, test_fold, test_fold_labels, data_fold\n",
    "        \n",
    "        rmspe_cv /= number_of_folds\n",
    "        \n",
    "        if len(grid_space) > 1:\n",
    "            scores.append(rmspe_cv)\n",
    "            alphas.append(alpha)\n",
    "            if rmspe_cv <= min_score:\n",
    "                min_score, min_alpha = rmspe_cv, alpha\n",
    "\n",
    "        print('CROSS-VALIDATED RMSPE = %1.8f on %d folds' % (rmspe_cv, number_of_folds), end='\\n\\n')\n",
    "\n",
    "    if len(grid_space) <= 1:\n",
    "        return rmspe_cv, predicted_labels, test_labels\n",
    "    else:\n",
    "        return alphas, scores, min_alpha, min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stacking_algorithm(predicted_labels):\n",
    "    return np.asarray(np.mean(predicted_labels, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data('train.csv', 'test.csv', 'store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_all_store_sales(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_mean_decomposition(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data and test_data have been constructed\n",
      "Memory usage of dataframe train_data is 162.67 Mb\n",
      "Memory usage of dataframe test_data is 11.99 Mb\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = main_feature_construction(data)\n",
    "test = data[1][['Id', 'Open']]\n",
    "print('train_data and test_data have been constructed')\n",
    "del data\n",
    "print('Memory usage of dataframe train_data is %3.2f Mb' % (train_data.memory_usage(index=True).sum()/(1024*1024)))\n",
    "print('Memory usage of dataframe test_data is %3.2f Mb' % (test_data.memory_usage(index=True).sum()/(1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE is working...\n",
      "alpha = 20\n",
      "some rmspe_score = 0.14243507"
     ]
    }
   ],
   "source": [
    "validation = True\n",
    "feature_selection = None\n",
    "# algorithms = ['rf', 'ridge', 'ens_rf', 'extrees', 'xgb']\n",
    "algorithms = ['ridge', 'ens_rf', 'xgb']\n",
    "stacker = False\n",
    "algorithm = 'ridge'\n",
    "\n",
    "\n",
    "if validation:\n",
    "    feature_selection = get_feature_selection(algorithm)\n",
    "    number_of_folds = 3\n",
    "    compute_optimal_alpha = True\n",
    "    \n",
    "    if compute_optimal_alpha:\n",
    "        \n",
    "#         grid_space = np.logspace(1.5, 2.3, num=10, base=10)\n",
    "#         grid_space = np.arange(0.1, 1, 0.1)\n",
    "        grid_space = np.arange(20, 101, 10)\n",
    "        alphas, scores, min_alpha, min_score = train_and_score(train_data, number_of_folds, grid_space=grid_space, \n",
    "                                                               feature_selection=feature_selection, algorithm=algorithm)\n",
    "        print('MIN_ALPHA =', min_alpha, 'MIN_RMSPE =', min_score)\n",
    "        pl.figure(figsize=(15,10))\n",
    "        pl.plot(alphas, scores, 'r.--')\n",
    "        del grid_space, scores, alphas\n",
    "    else:\n",
    "        if stacker:\n",
    "            stacking_predicted_labels = []\n",
    "            test_labels = []\n",
    "            for alg in algorithms:\n",
    "                feature_selection = get_feature_selection(alg)\n",
    "                rmspe_cv, predicted_labels, test_labels = train_and_score(train_data, number_of_folds, algorithm=alg,\n",
    "                                                                          feature_selection=feature_selection, \n",
    "                                                                          print_importances=False)\n",
    "                stacking_predicted_labels.append(predicted_labels)\n",
    "            rmspe_cv = 0.\n",
    "            for cv in range(number_of_folds):\n",
    "                predicted_labels = stacking_algorithm(np.asarray([x[cv] for x in stacking_predicted_labels]))\n",
    "                rmspe_score = compute_RMSPE(test_labels[cv], predicted_labels)\n",
    "                rmspe_cv += rmspe_score\n",
    "            rmspe_cv /= number_of_folds\n",
    "            print('\\nOVERALL STACKING RMSPE on', number_of_folds, 'folds is', rmspe_cv)\n",
    "            del stacking_predicted_labels, test_labels\n",
    "        else:\n",
    "            rmspe_cv, predicted_labels, test_labels = train_and_score(train_data, number_of_folds, algorithm=algorithm,\n",
    "                                                                      feature_selection=feature_selection)\n",
    "    \n",
    "\n",
    "elif not validation:\n",
    "    if stacker:\n",
    "        stacking_predicted_labels = []\n",
    "        for alg in algorithms:\n",
    "            print(str(alg).upper(), 'is working...')\n",
    "            feature_selection = get_feature_selection(alg)\n",
    "            train_array, train_array_labels, test_array, feature_names, \\\n",
    "            train_store_indices, test_store_indices = get_all_data(train_data, test_data,\n",
    "                                                                   feature_selection=feature_selection, \n",
    "                                                                   algorithm=alg)\n",
    "            test_predicted_labels = fit_predict_model(train_array, train_array_labels, test_array, algorithm=alg,\n",
    "                                                      feature_names=feature_names, print_importances=None,\n",
    "                                                      train_store_indices=train_store_indices,\n",
    "                                                      test_store_indices=test_store_indices)\n",
    "            stacking_predicted_labels.append(test_predicted_labels)\n",
    "        test_predicted_labels = stacking_algorithm(stacking_predicted_labels)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        feature_selection = get_feature_selection(algorithm)\n",
    "        train_array, train_array_labels, test_array, feature_names, \\\n",
    "        train_store_indices, test_store_indices = get_all_data(train_data, test_data, feature_selection=feature_selection, \n",
    "                                                               algorithm=algorithm)\n",
    "        test_predicted_labels = fit_predict_model(train_array, train_array_labels, test_array, algorithm=algorithm,\n",
    "                                                  feature_names=feature_names, print_importances=True,\n",
    "                                                  train_store_indices=train_store_indices,\n",
    "                                                  test_store_indices=test_store_indices)\n",
    "    test['Sales'] = test_predicted_labels\n",
    "    del train_array, train_array_labels, test_array, feature_names, test_predicted_labels\n",
    "    test.ix[test.Open == 0, 'Sales'] = 0\n",
    "    if stacker:\n",
    "        filename = 'prediction_stacker.csv' \n",
    "    else:\n",
    "        filename = 'prediction_' + algorithm + '.csv'\n",
    "    test[['Id', 'Sales']].to_csv(filename, index=False)\n",
    "    print('\\nResult was written to', filename)\n",
    "    del test['Sales']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['CompetitionDistance', 'Promo', 'Store', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'DiffCompetitionYear', 'Promo2SinceWeek', 'DayOfWeek_6', 'DiffToday', 'DayOfWeek_1', 'DiffNewYear', 'DiffFoolDay', 'StoreType_a', 'Day', 'DayOfYear', 'StoreType_b', 'Assortment_a', 'StoreType_d', 'CompetitionOpenSinceMonth_3', 'StoreType_c', 'Assortment_c', 'CompetitionOpenSinceMonth_5', 'DayMonthChange', 'CompetitionOpenSinceMonth_9', 'CompetitionOpenSinceMonth_8', 'CompetitionOpenSinceMonth_4', 'CompetitionOpenSinceMonth_12', 'CompetitionOpenSinceMonth_11', 'PromoInterval_3', 'CompetitionOpenSinceMonth_7', 'DayOfWeek_7', 'CompetitionOpenSinceMonth_10', 'CompetitionOpenSinceMonth_6', 'CompetitionOpenSinceMonth_2', 'CompetitionOpenSinceMonth_0', 'DayOfWeek_5', 'PromoInterval_1', 'PromoInterval_2', 'PromoInterval_0', 'CompetitionOpenSinceMonth_1', 'DayOfWeek_2', 'DayMonthAfterMiddle', 'Year_2013', 'SchoolHoliday', 'DayOfWeek_4', 'DayOfWeek_3', 'Month_12', 'Year_2014', 'Week_0', 'Month_5', 'Week_3', 'Week_2', 'Week_1', 'Year_2015', 'Assortment_b', 'Month_4', 'Month_7', 'Month_3', 'Month_9', 'Month_6', 'Month_8', 'StateHoliday_0', 'Month_2', 'Month_10', 'Month_1', 'Month_11', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c']"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
